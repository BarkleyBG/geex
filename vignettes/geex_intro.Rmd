---
title: "Estimating Equations in R: `geex`"
author: "B. Saul"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE, message = FALSE, warning=FALSE}
library(geex)
library(dplyr)
library(inferference)
library(sandwich)
library(xtable)
# library(microbenchmark)
```

M-estimation theory provides a framework for asympotic properties of estimators that are solutions to estimating equations. Regression methods such as Generalized Linear Models (GLM) and Generalized Estimating Equations (GEE) fit in this framework.  Countless R packages implement specific applications of estimating equations. A common reason to use M-estimation is to compute the empirical sandwich variance estimator - an asymptotically Normal and "robust" covariance. Many packages compute this variance estimator automatically, and packages such as `sandwich` take the output of other modeling methods to compute this variance estimate. 

`geex` aims to be provide a more general framework that any modelling method can use to compute point and variance estimates for parameters that are solutions to estimating equations. The basic idea:

* Analyst provides three things: (1) data, (2) instructions on how to split the data into independent units and (3) a function that takes unit-level data and returns a function in terms of parameters.
* `geex` computes point estimates and variance estimates for the parameters.

## Basic Setup

I mostly follow the notation of Stefanski and Boos. I tried to keep notation in the code similar to mathematical notation.

Suppose we have $m$ independent or nearly independent units of observations.

\[
\sum_{i = 1}^m \psi(O_i, \theta) = 0
\]

Where $\psi$ is vector of length $p$ corresponding to the number of parameters in $\theta$.

For notational ease, let $\psi(O_i, \theta) = \psi_i$ Let:
\[
A_i = - \frac{\partial \psi(O_i, \theta)}{\partial \theta}
\]

\[
A = \sum_{i = 1}^m A_i
\]

\[
B_i = \psi_i \psi_i^T
\]

\[
B = \sum_{i = 1}^m B_i
\]

\[
\Sigma = A^{-1} B \{A^{-1}\}^T
\]

## Stefanski \& Boos example 1

```{r SB1_setup, echo=FALSE}
n  <- 100
mu <- 5
sigma2 <- 4
dt <- data.frame(Y = rnorm(n, mean = mu, sd = sigma2), id = 1:n)
split_data <- split(dt, dt$id)
```

Example 1 illustrates calculation of sample mean and variance using estimating equations. I generate a data set with `r n` observations drawn from a Normal(`r mu`, `r sigma2`) distribution. Table 1 translated the estimating equations into the R function needed for `geex`:

<table>
<tr>
<td>
\[
\psi(Y_i, \theta) = 
\begin{pmatrix}
Y_i - \theta_1 \\
(Y_i - \theta_1)^2 - \theta_2
\end{pmatrix}
\] 
</td>
<td>
```{r SB1_eefun, echo=TRUE, results='asis'}
SB1_eefun <- function(data){
  function(theta){
    with(data,
      c(Y - theta[1],
       (Y - theta[1])^2 - theta[2] )
    )
  }
}
```
</td>
</tr>
</table>

With the `eeFUN` function prepared, it is passed to `estimate_equations` along with the data, a character string naming the variable that identifies groups within the dataset, and starting values for the root finder.

```{r SB1_run, echo=FALSE}
estimates <- estimate_equations(eeFUN = SB1_eefun, data  = dt, units = 'id', roots = c(1,1))
```

```{r SB1_clsform, echo=FALSE}
## Compare to closed form ##

A <- diag(1, nrow = 2)

B <- with(dt, {
  Ybar <- mean(Y)
  B11 <- mean( (Y - Ybar)^2 )
  B12 <- mean( (Y - Ybar) * ((Y - Ybar)^2 - B11) )
  B22 <- mean( ((Y - Ybar)^2 - B11)^2 )
  matrix(
    c(B11, B12,
      B12, B22), nrow = 2
  )
})

## closed form roots
# note that var() divides by n - 1, not n
theta_cls <- summarize(dt, p1 = mean(Y), p2 = var(Y) * (n() - 1)/ n() )

# closed form
Sigma_cls <- (solve(A) %*% B %*% t(solve(A))) / n
```

```{r}

```

|      | Closed form | `geex` |
|------|------|------|  
| $\hat{\theta}$ | `r theta_cls` | `r estimates$parameters` |
| $\hat{\Sigma}$ | `r Sigma_cls` | `r print(xtable(estimates$vcov), floating=FALSE, tabular.environment="pmatrix", hline.after=NULL, include.rownames=FALSE, include.colnames=FALSE)` |


## Stefanski \& Boos example 2

```{r SB_example2, echo=TRUE}
n  <- 100
dt <- data.frame(Y  = rnorm(n, mean = 5, sd = 4), 
                 X  = rnorm(n, mean = 2, sd = .09),
                 id = 1:n)
split_data <- split(dt, dt$id)

SB_ex2_eefun <- function(data){
  function(theta){
    with(data,
      c(Y - theta[1],
        X - theta[2],
        theta[1] - (theta[3] * theta[2]) )
    )
  }
}

example <- list(eeFUN   = SB_ex2_eefun, 
                splitdt = split_data)
root <- eeroot(obj = example, start = c(1, 1, 1))$root
mats  <- compute_matrices(obj = example,
                          theta = root,
                          numDeriv_options = list(method = 'Richardson'))
Sigma <- compute_sigma(mats)

## Compare to closed form ##

A <- with(dt, {
 matrix(
  c(1 , 0, 0,
    0 , 1, 0,
    -1, mean(Y)/mean(X), mean(X)),
  byrow = TRUE, nrow = 3)
})

B <- with(dt, {
  matrix(
    c(var(Y)   , cov(Y, X), 0,
      cov(Y, X), var(X)   , 0,
      0, 0, 0),
    byrow = TRUE, nrow = 3)
})

## geex roots 
root

## closed form roots
summarize(dt, p1 = mean(Y), p2 = mean(X), p3 = p1/p2)

# geex variance estimate
Sigma

# closed form
(solve(A) %*% B %*% t(solve(A))) / n

```

## Stefanski \& Boos example 3

Closed form variance is complicated, so didn't do for now.

```{r SB_example3, echo=TRUE}
set.seed(100) # running into issue where sqrt(theta2) and log(theta2) return NaN for some seeds
n  <- 100
dt <- data.frame(Y  = rnorm(n, mean = 5, sd = 4), 
                 id = 1:n)
split_data <- split(dt, dt$id)

SB_ex3_eefun <- function(data){
  function(theta){
    with(data,
      c(Y - theta[1],
       (Y - theta[1])^2 - theta[2],
       sqrt(theta[2]) - theta[3],
       log(theta[2]) - theta[4])
    )
  }
}

example <- list(eeFUN   = SB_ex3_eefun, 
                splitdt = split_data)
theta_geex <- eeroot(obj = example, start = c(1, 1, 1, 1))$root


mats  <- compute_matrices(obj = example,
                          theta = theta_geex,
                          numDeriv_options = list(method = 'Richardson'))
Sigma <- compute_sigma(mats)

## geex roots 
theta_geex

## closed form roots
theta_cls <- summarize(dt, p1 = mean(Y), p2 = sum((Y - p1)^2)/n(), p3 = sqrt(p2), p4 = log(p2))

# geex variance estimate
Sigma

## Closed form variance
theta2 <- theta_cls$p2
mu3 <- moments::moment(dt$Y, order = 3, central = TRUE)
mu4 <- moments::moment(dt$Y, order = 4, central = TRUE)
A <- matrix(c(1, 0, 0, 0,
              0, 1, 0, 0,
              0, -1/(2 * sqrt(theta2)), 1, 0,
              0, -1/theta2, 0, 1), 
            byrow = TRUE, nrow = 4)
B <- matrix(c(1/theta2, mu3/(2 * theta2^3), 0, 0,
              mu3/(2 * theta2^3), (mu4 - theta2^2)/(4 * theta2^4), 0, 0,
              0, 0, 0, 0,
              0, 0, 0, 0),
            byrow = TRUE, nrow = 4)
# closed form estimators for 
(solve(A) %*% B %*% t(solve(A))) / n

Sigma
(mu4 - theta2^2)/(4*theta2)/100
(mu4/(theta2^2) - 1)/100

```


## Stefanski \& Boos example 4

```{r SB_example4, echo=TRUE}
n  <- 10000

# Oracle parms
alpha <- 2
beta  <- 3
gamma <- 2
delta <- 1.5
e1 <- e2 <- e3 <- rnorm(n)
sigma_e <- 1
sigma_U <- .25
sigma_tau <- 1
### Random variables

X <- rgamma(n, shape = 5)
X <- rnorm(n, sd = 1)

dt <- data.frame(Y  = alpha + (beta * X) + (sigma_e * e1), 
                 W  = X + (sigma_U * e2),
                 T_  = gamma + (delta * X) + (sigma_tau * e3),
                 id = 1:n)
split_data <- split(dt, dt$id)

SB_ex4_eefun <- function(data){
  function(theta){
    with(data,
      c(theta[1] - T_,
        theta[2] - W,
        (Y - (theta[3] * W)) * (theta[2] - W),
        (Y - (theta[4] * W)) * (theta[1] - T_))
    )
  }
}



example <- list(eeFUN   = SB_ex4_eefun, 
                splitdt = split_data)
root <- eeroot(obj = example, start = c(1, 1, 1, 1))$root
root

## compare to closed form
c(theta1 = mean(dt$T_),
  theta2 = mean(dt$W),
  theta3 = coef(lm(Y ~ W, data = dt))[2],
  theta4 = coef(lm(Y ~ T_, data = dt))[2]/coef(lm(W ~ T_, data = dt))[2])


mats  <- compute_matrices(obj = example,
                          theta = root,
                          numDeriv_options = list(method = 'Richardson'))
Sigma <- compute_sigma(mats)

Sigma


## compare to closed form
# TODO

```

## Stefanski \& Boos example 5

```{r SB_example5, echo=TRUE}

n <- 100
theta0 <- 0
dt <- data.frame(X = rnorm(n, mean = 2),
                 id = 1:n)
split_data <- split(dt, dt$id)

F0 <- function(y, theta0, distrFUN = pnorm){
  distrFUN(y - theta0, mean = 0)
}

f0 <- function(y, densFUN){
  densFUN(y, mean = 0)
}

integrand <- function(y, densFUN = dnorm){
  f0(y, densFUN = densFUN)^2
}

IC_denom <- integrate(integrand, lower = -Inf, upper = Inf)$value


SB_ex5_eefun <- function(data, theta0 = 0){
  Xi <- data$X
  IC_HL <- (1/IC_denom) * (F0(Xi, theta0) - 0.5)
  function(theta){
     c(IC_HL - (theta[1] - theta0), #psi for HL estimator
       Xi - theta[2]) # psi for sample mean
  }
}


example <- list(eeFUN   = SB_ex5_eefun, 
                splitdt = split_data)

root <- eeroot(obj = example, start = c(1, 1))$root
root

X <- dt$X
pair_means <- numeric(length(dt$X) - 1)
for(i in 1:(length(X) - 1)){
 pair_means[i] <-  (X[i] + X[i + 1])/2
}

c(median(pair_means), mean(dt$X))

# Asymp correlation btn HL estimator and mean
mats  <- compute_matrices(obj = example,
                          theta = root,
                          numDeriv_options = list(method = 'Richardson'))
Sigma <- compute_sigma(mats)
Sigma


```


## Stefanski \& Boos example 6

```{r SB_example6, echo=TRUE}


```


## Stefanski \& Boos example 7

```{r SB_example7, echo=TRUE}


```

## Stefanski \& Boos example 8

```{r SB_example8, echo=TRUE}
n <- 50
beta <- c(0.5, 2)
dt <- data_frame(X  = rep(0:1, each = n/2),
                 e  = rnorm(n),
                 Y  = as.numeric(cbind(1, X) %*% beta) + e,
                 id = 1:n)
split_data <- split(dt, dt$id)

psi_k <- function(x, k = 1.345){
  if(abs(x) <= k) x else sign(x) * k
}

SB_ex8_eefun <- function(data){
  Yi <- data$Y
  xi <- model.matrix(Y ~ X, data = data)
  function(theta){
    r <- Yi - xi %*% theta
    c(psi_k(r) %*% xi)
  }
}

example <- list(eeFUN   = SB_ex8_eefun, 
                splitdt = split_data)

root <- eeroot(obj = example, start = c(1, 2))$root


m <- MASS::rlm(Y ~ X, data = dt, method = 'M')

# Compare paramter estimates
root # GEEX
coef(m) # rlm

# Asymp correlation btn HL estimator and mean
mats  <- compute_matrices(obj = example,
                          theta = root,
                          numDeriv_options = list(method = 'Richardson'))
Sigma <- compute_sigma(mats)

# Compare variance
Sigma
vcov(m)

```


## Stefanski \& Boos example 9

```{r SB_example9, echo=TRUE}
n <- 100
beta <- c(0.5, 2, .1)

dt <- data_frame(X1 = rep(0:1, each = n/2), 
                 X2 = rep(0:1, times = n/2),
                 Y  = rbinom(n, 1, prob = as.numeric(plogis(cbind(1, X1, X2) %*% beta))),
                 id = 1:n)
split_data <- split(dt, dt$id)

SB_ex9_eefun <- function(data){
  Yi <- data$Y
  xi <- model.matrix(Y ~ X1 + X2, data = data, drop = FALSE)
  function(theta){
    lp <- xi %*% theta
    mu <- plogis(lp)
    D  <- t(xi) %*% dlogis(lp)
    V  <- mu * (1 - mu)
    D %*% solve(V) %*% (Yi - mu)
  }
}

# SB_ex9_eefun(split_data[[6]])(c(.5, 2, .1))

example <- list(eeFUN   = SB_ex9_eefun, 
                splitdt = split_data)

root <- eeroot(obj = example, start = c(.5, 2, 1))$root
m <- glm(Y ~ X1 + X2, data = dt, family = binomial(link = 'logit'))

# Compare parameter estimates
root
coef(m)
mats <- compute_matrices(example, theta = root)
Sigma <- compute_sigma(mats)

# Compare variance estimates
Sigma
sandwich(m)
```



## Stefanski \& Boos example 10

```{r SB_example10, echo=TRUE}

dt <- data_frame(game = 1:23,
                 ft_made = c(4, 5, 5, 5, 2, 7, 6, 9, 4, 1, 13, 5, 6, 9, 7, 3, 8, 1, 18, 3, 10, 1, 3),
                 ft_attp = c(5, 11, 14, 12, 7, 10, 14, 15, 12, 4, 27, 17, 12, 9, 12, 10, 12, 6, 39, 13, 17, 6, 12))

split_data <- split(dt, dt$game)

SB_ex10_eefun <- function(data){
  Y <- data$ft_made
  n <- data$ft_attp
  function(theta){
    p <- theta[2]
    c(((Y - (n * p))^2)/(n * p * (1 - p))  - theta[1], 
      Y - n * p)
  }
}
SB_ex10_eefun(split_data[[1]])(c(.5, .5))
example <- list(eeFUN   = SB_ex10_eefun, 
                splitdt = split_data)

root <- eeroot(obj = example, start = c(.5, .5))$root
root

V11 <- function(p) {
  k <- length(nrow(dt))
  sumn <- sum(dt$ft_attp)
  sumn_inv <- sum(1/dt$ft_attp)
  term2_n <- 1 - (6 * p) + (6 * p^2)
  term2_d <- p * (1 - p) 
  term2 <- term2_n/term2_d
  print(term2)
  term3 <- ((1 - 2 * p)^2)/( (sumn/k) * p * (1 - p))
  print(term3)
  2 + (term2 * (1/k) * sumn_inv)  - term3
}

### ???? I keep getting a negative value for V11

p_tilde <- sum(dt$ft_made)/sum(dt$ft_attp)
V <- V11(.45)
V
pnorm(root[1], mean = 1, sd = sqrt(V))

```


## Small Sample Corrections of Fay (2001)

### Bias correction

\[
H_i = \{1 - min(b, \{A_i A\}_{jj}) \}^{-1/2}
\]
Where $b$ is a constant chosen by the analyst. Fay lets $b = 0.75$. Note that $H_i$ is a diagonal matrix.

\[
B^{bc}_i = H_i \psi_i \psi_i^T H_i
\]

\[
B^{bc} = \sum_{i = 1}^m B^{bc}_i
\]

\[
\Sigma^{bc} = A^{-1} B^{bc} \{A^{-1}\}^T
\]

### Degrees of Freedom corrections

Let $L$ be the contrast of interest (e.g.) $(0, \dots, 0, 1, -1)$ for a causal difference when the last two elements of the estimating equations are the counterfactual means.

\[
\mathcal{I} = [I_p \cdots I_p]
\]

where $I_p$ is a $p \times p$ identity matrix.

\[
G = I_{pm} - \begin{bmatrix}A^{bc}_1 \\ \vdots \\ A_m \end{bmatrix} A^{-1} \mathcal{I} 
\]

\[
M = diag\{H_i A^{-1} L L^T (A^{-1})^T H_i \}
\]

\[
C = G^T M G
\]

\[
w_i = L^T \left[ \left\{\sum_{j \neq i} A_i \right\}^{-1} - A^{-1} \right] L
\]

\[
\bar{w} = \sum_{i = 1}^m w_i
\]

\[
A^{bc}_i = \frac{w_i}{\bar{w}} B^{bc}
\]

\[
\hat{df}_1 = \frac{ \left\{ Tr( diag(A_i) C ) \right\}^2  }{ Tr( diag(A_i) C diag(A_i) C)}  
\]

\[
\hat{df}_2 = \frac{ \left\{ Tr( diag(A^{bc}_i) C ) \right\}^2  }{ Tr( diag(A^{bc}_i) C diag(A^{bc}_i) C)}  
\]

